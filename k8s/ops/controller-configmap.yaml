apiVersion: v1
kind: ConfigMap
metadata:
  name: news-analyzer-backfill-controller-scripts
  namespace: news-analyzer
  labels:
    app: news-analyzer
    component: ops-backfill-controller
data:
  controller.sh: |-
    #!/usr/bin/env bash
    set -euo pipefail
    
    ns=${NAMESPACE:-news-analyzer}
    start=${START:-2025-01-01}
    end=${END:-2025-12-31}
    split=${SPLIT:-weekly}
    pubs=${PUBLICATIONS:-"Smyth County News & Messenger,The News & Press,The Bland County Messenger,The Floyd Press,Wytheville Enterprise,Washington County News"}
    force=${FORCE:-1}
    max_new=${MAX_NEW_PER_RUN:-4}
    req_cpu=${REQ_CPU:-2}
    req_mem=${REQ_MEM:-1Gi}
    lim_cpu=${LIM_CPU:-2}
    lim_mem=${LIM_MEM:-3Gi}
    pw_trace=${PW_TRACE:-0}
    par=${SCRAPER_PARALLELISM:-2}
    loop_sleep=${LOOP_SLEEP:-600}
    
    while true; do
      # auto-tune if OOMs seen
      oom=$(kubectl get pods -n "$ns" -l component=scraper,type=backfill -o json 2>/dev/null | grep -c OOMKilled || true)
      if [ "$oom" -gt 0 ]; then par=1; lim_mem=4Gi; fi
    
      # capacity from quota
      limit=$(kubectl get resourcequota news-analyzer-quota -n "$ns" -o jsonpath='{.status.hard.count/jobs\.batch}' 2>/dev/null || true)
      [ -z "$limit" ] && limit=40
      used=$(kubectl get jobs -n "$ns" --no-headers 2>/dev/null | wc -l | tr -d ' ')
      cap=$((limit - used)); [ $cap -lt 0 ] && cap=0; [ $cap -gt $max_new ] && cap=$max_new
      created=0
    
      cur="$start"
      while true; do
        # stop if capacity reached or past end date
        if [ $created -ge $cap ]; then break; fi
        if [ $(date -d "$cur" +%s) -gt $(date -d "$end" +%s) ]; then break; fi
        # compute window
        if [ "$split" = "daily" ]; then
          win_s="$cur"; win_e="$cur"
        elif [ "$split" = "biweekly" ]; then
          win_s="$cur"; win_e=$(date -d "$cur +13 days" +%Y-%m-%d); [ "$win_e" \> "$end" ] && win_e="$end"
        else
          win_s="$cur"; win_e=$(date -d "$cur +6 days" +%Y-%m-%d); [ "$win_e" \> "$end" ] && win_e="$end"
        fi
    
        # require Wed/Sat
        keep=0; d="$win_s"; while [ $(date -d "$d" +%s) -le $(date -d "$win_e" +%s) ]; do dow=$(date -d "$d" +%u); [ "$dow" = "3" -o "$dow" = "6" ] && keep=1 && break; d=$(date -d "$d +1 day" +%Y-%m-%d); done
        ws=$(date -d "$win_s" +%Y%m%d); we=$(date -d "$win_e" +%Y%m%d)
        if [ $keep -eq 1 ]; then
          # create scraper job if missing
          if ! kubectl get jobs -n "$ns" -l component=scraper,type=backfill,win-start=$ws,win-end=$we -o name | grep -q .; then
            cat <<EOF | kubectl create -f -
    apiVersion: batch/v1
    kind: Job
    metadata:
      generateName: scraper-backfill-
      namespace: $ns
      labels:
        app: news-analyzer
        component: scraper
        type: backfill
        win-start: "$ws"
        win-end: "$we"
    spec:
      backoffLimit: 0
      ttlSecondsAfterFinished: 172800
      template:
        metadata:
          labels:
            app: news-analyzer
            component: scraper
            type: backfill
            win-start: "$ws"
            win-end: "$we"
        spec:
          restartPolicy: Never
          serviceAccountName: news-analyzer-ops-bot
          imagePullSecrets:
          - name: harbor-regcred
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            fsGroup: 1000
          volumes:
          - name: session-storage
            emptyDir: {}
          - name: scraper-login-override
            configMap:
              name: scraper-login-override
          - name: scraper-discover-override
            configMap:
              name: scraper-discover-override
          containers:
          - name: scraper
            image: registry.harbor.lan/library/news-analyzer-scraper:latest
            imagePullPolicy: Always
            env:
            - name: PW_TRACE
              value: "$pw_trace"
            - name: SCRAPER_PARALLELISM
              value: "$par"
            - name: HOME
              value: /home/scraper
            - name: PLAYWRIGHT_BROWSERS_PATH
              value: /home/scraper/.cache/ms-playwright
            - name: EEDITION_USER
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: EEDITION_USER
            - name: EEDITION_PASS
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: EEDITION_PASS
            - name: SMARTPROXY_USERNAME
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: SMARTPROXY_USERNAME
            - name: SMARTPROXY_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: SMARTPROXY_PASSWORD
            - name: SMARTPROXY_HOST
              valueFrom:
                configMapKeyRef:
                  name: news-analyzer-config
                  key: SMARTPROXY_HOST
            - name: MINIO_ENDPOINT
              valueFrom:
                configMapKeyRef:
                  name: news-analyzer-config
                  key: MINIO_ENDPOINT
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: MINIO_ACCESS_KEY
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: MINIO_SECRET_KEY
            - name: MINIO_BUCKET
              valueFrom:
                configMapKeyRef:
                  name: news-analyzer-config
                  key: MINIO_BUCKET
            - name: SCRAPER_USER_AGENT
              valueFrom:
                configMapKeyRef:
                  name: news-analyzer-config
                  key: SCRAPER_USER_AGENT
            - name: START_DATE
              value: "$win_s"
            - name: END_DATE
              value: "$win_e"
            - name: FORCE_DOWNLOAD
              value: "$force"
            - name: PUBLICATIONS
              value: "$pubs"
            resources:
              requests:
                memory: "$req_mem"
                cpu: "$req_cpu"
              limits:
                memory: "$lim_mem"
                cpu: "$lim_cpu"
            volumeMounts:
            - name: session-storage
              mountPath: /app/storage
            - name: scraper-login-override
              mountPath: /app/scraper/login.py
              subPath: login.py
            - name: scraper-discover-override
              mountPath: /app/scraper/discover.py
              subPath: discover.py
            command:
            - /bin/sh
            - -c
            - |
              set -e
              mkdir -p /app/storage
              python - <<'PY' > /tmp/download-dates.txt
              from datetime import datetime, timedelta
              import os
              start = datetime.strptime(os.environ['START_DATE'], '%Y-%m-%d').date()
              end = datetime.strptime(os.environ['END_DATE'], '%Y-%m-%d').date()
              cur = start
              while cur <= end:
                  if cur.weekday() in (2, 5):
                      print(cur.isoformat())
                  cur += timedelta(days=1)
              PY
              PUB_LIST=\${PUBLICATIONS:-"$pubs"}
              while read d; do
                [ -z "\$d" ] && continue
                echo "Processing edition \$d"
                extra=""; [ "\${FORCE_DOWNLOAD:-1}" = "1" ] && extra="--force"
                OLD_IFS="\$IFS"; IFS=,; for pub in \$PUB_LIST; do
                  pub_trim=$(echo "\$pub" | sed -e "s/^ *//" -e "s/ *$//")
                  [ -z "\$pub_trim" ] && continue
                  echo "  -> \$pub_trim"
                  python -m scraper.downloader --date "\$d" \$extra --publication "\$pub_trim" --storage /app/storage/storage_state.json
                  sleep 1
                done; IFS="\$OLD_IFS"
              done < /tmp/download-dates.txt
    EOF
            created=$((created+1))
          fi
    
          # extractor job if missing
          if ! kubectl get jobs -n "$ns" -l component=extractor,type=backfill,win-start=$ws,win-end=$we -o name | grep -q .; then
            cat <<EOF | kubectl create -f -
    apiVersion: batch/v1
    kind: Job
    metadata:
      generateName: extractor-backfill-
      namespace: $ns
      labels:
        app: news-analyzer
        component: extractor
        type: backfill
        win-start: "$ws"
        win-end: "$we"
    spec:
      backoffLimit: 0
      ttlSecondsAfterFinished: 172800
      template:
        metadata:
          labels:
            app: news-analyzer
            component: extractor
            type: backfill
            win-start: "$ws"
            win-end: "$we"
        spec:
          restartPolicy: Never
          imagePullSecrets:
          - name: harbor-regcred
          containers:
          - name: extractor
            image: registry.harbor.lan/library/news-analyzer-extractor:latest
            imagePullPolicy: Always
            env:
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: DATABASE_URL
            - name: MINIO_ENDPOINT
              valueFrom:
                configMapKeyRef:
                  name: news-analyzer-config
                  key: MINIO_ENDPOINT
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: MINIO_ACCESS_KEY
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: MINIO_SECRET_KEY
            - name: MINIO_BUCKET
              valueFrom:
                configMapKeyRef:
                  name: news-analyzer-config
                  key: MINIO_BUCKET
            resources:
              requests:
                memory: 1Gi
                cpu: 500m
              limits:
                memory: 2Gi
                cpu: 1000m
            command:
            - /bin/sh
            - -c
            - |
              set -e
              python - <<'PY' > /tmp/dates.txt
              import os
              from datetime import datetime, timedelta
              start = datetime.strptime(os.environ.get('START_DATE','${win_s}'), '%Y-%m-%d').date()
              end = datetime.strptime(os.environ.get('END_DATE','${win_e}'), '%Y-%m-%d').date()
              cur = start
              while cur <= end:
                  print(cur.isoformat())
                  cur += timedelta(days=1)
              PY
              while read d; do
                echo "Extracting \$d"
                python -m processor --date "\$d"
              done < /tmp/dates.txt
    EOF
          fi
        fi
        cur=$(date -d "$win_e +1 day" +%Y-%m-%d)
      done
    
      echo "controller: sleep $loop_sleep sec"; sleep "$loop_sleep"
    done
