apiVersion: v1
kind: ConfigMap
metadata:
  name: news-analyzer-ops-scripts
  namespace: news-analyzer
  labels:
    app: news-analyzer
    component: ops
data:
  health_check.py: |
    import os
    import socket
    import sys
    import time
    from datetime import datetime

    import requests
    from kubernetes import client, config

    try:
      import psycopg2  # type: ignore
    except Exception:  # pragma: no cover
      psycopg2 = None

    NAMESPACE = os.getenv("NAMESPACE", "news-analyzer")
    NTFY_URL = os.getenv("NTFY_URL", "http://ntfy-service.news-analyzer.svc.cluster.local")
    NTFY_TOPIC = os.getenv("NTFY_TOPIC", "news-analyzer-health")

    SUMMARIZER_URL = os.getenv(
        "SUMMARIZER_URL",
        "http://news-analyzer-summarizer-service.news-analyzer.svc.cluster.local:8000/health",
    )
    MINIO_HEALTH_URL = os.getenv(
        "MINIO_HEALTH_URL",
        "http://minio-service.news-analyzer.svc.cluster.local:9000/minio/health/live",
    )
    DATABASE_URL = os.getenv("DATABASE_URL")

    def load_kube_config():
        try:
            config.load_incluster_config()
        except Exception:
            config.load_kube_config()

    def count_pods(v1: client.CoreV1Api):
        pods = v1.list_namespaced_pod(NAMESPACE)
        total = len(pods.items)
        running = sum(1 for p in pods.items if (p.status and p.status.phase == "Running"))
        return running, total

    def count_oom_killed(v1: client.CoreV1Api):
        pods = v1.list_namespaced_pod(NAMESPACE, label_selector="component=scraper,type=backfill").items
        cnt = 0
        for p in pods:
            if not p.status or not p.status.container_statuses:
                continue
            for cs in p.status.container_statuses:
                term = (cs.last_state and cs.last_state.terminated) or (cs.state and cs.state.terminated)
                if term and getattr(term, "reason", "") == "OOMKilled":
                    cnt += 1
                    break
        return cnt

    def count_pending_jobs(b1: client.BatchV1Api):
        jobs = b1.list_namespaced_job(NAMESPACE)
        pending = 0
        for j in jobs.items:
            s = j.status
            # Consider pending if not succeeded yet
            if not s or not s.succeeded:
                pending += 1
        return pending

    def check_http(url: str, timeout: float = 5.0) -> bool:
        try:
            r = requests.get(url, timeout=timeout)
            return r.ok
        except Exception:
            return False

    def check_postgres(url: str, timeout: float = 5.0) -> bool:
        if not url or psycopg2 is None:
            return False
        try:
            conn = psycopg2.connect(url, connect_timeout=timeout)
            cur = conn.cursor()
            cur.execute("SELECT 1;")
            cur.fetchone()
            cur.close()
            conn.close()
            return True
        except Exception:
            return False

    def notify_ntfy(title: str, message: str, priority: int = 3, tags: str = "health"):
        try:
            topic_url = f"{NTFY_URL.rstrip('/')}/{NTFY_TOPIC}"
            headers = {
                "Title": title,
                "Priority": str(priority),
                "Tags": tags,
            }
            requests.post(topic_url, data=message.encode("utf-8"), headers=headers, timeout=5.0)
        except Exception:
            # Best-effort notification
            pass

    def main():
        load_kube_config()
        v1 = client.CoreV1Api()
        b1 = client.BatchV1Api()

        running, total = count_pods(v1)
        pending_jobs = count_pending_jobs(b1)
        oom = count_oom_killed(v1)

        summarizer_ok = check_http(SUMMARIZER_URL)
        minio_ok = check_http(MINIO_HEALTH_URL)
        pg_ok = check_postgres(DATABASE_URL) if DATABASE_URL else False

        status = "healthy"
        tags = ["health", "ok"]
        priority = 1

        if (running < total) or (not summarizer_ok) or (not minio_ok) or (not pg_ok):
            status = "degraded"
            tags = ["health", "warning"]
            priority = 3

        msg = (
            f"Health: {status} | Pods: {running}/{total} | Pending Jobs: {pending_jobs} | OOMKilled(backfill): {oom} | "
            f"Summarizer: {'OK' if summarizer_ok else 'FAIL'} | "
            f"MinIO: {'OK' if minio_ok else 'FAIL'} | "
            f"PostgreSQL: {'OK' if pg_ok else 'FAIL'} | "
            f"Time: {datetime.utcnow().isoformat()}Z"
        )

        print(msg)
        notify_ntfy("ðŸ¥ System Health Check", msg, priority=priority, tags=",".join(tags))

    if __name__ == "__main__":
        main()

  cleanup.py: |
    import os
    from datetime import datetime, timedelta, timezone

    from kubernetes import client, config

    NAMESPACE = os.getenv("NAMESPACE", "news-analyzer")
    SUCCESS_TTL_DAYS = int(os.getenv("JOB_SUCCESS_TTL_DAYS", "7"))
    FAILED_TTL_DAYS = int(os.getenv("JOB_FAILED_TTL_DAYS", "3"))

    def load_kube_config():
        try:
            config.load_incluster_config()
        except Exception:
            config.load_kube_config()

    def main():
        load_kube_config()
        b1 = client.BatchV1Api()
        core = client.CoreV1Api()

        now = datetime.now(timezone.utc)

        # Clean completed jobs older than SUCCESS_TTL_DAYS
        jobs = b1.list_namespaced_job(NAMESPACE).items
        for j in jobs:
            s = j.status
            if s and s.succeeded:
                ct = s.completion_time
                if ct and (now - ct.replace(tzinfo=timezone.utc)) > timedelta(days=SUCCESS_TTL_DAYS):
                    print(f"Deleting completed job {j.metadata.name}")
                    try:
                        b1.delete_namespaced_job(
                            name=j.metadata.name,
                            namespace=NAMESPACE,
                            propagation_policy="Background",
                        )
                    except Exception as e:
                        print(f"Failed to delete job {j.metadata.name}: {e}")

        # Clean failed jobs older than FAILED_TTL_DAYS
        for j in jobs:
            s = j.status
            if s and s.failed:
                # Try lastTransitionTime on conditions
                ts = None
                if s.conditions:
                    for c in s.conditions:
                        if c.type == "Failed" and c.last_transition_time:
                            ts = c.last_transition_time
                            break
                if ts and (now - ts.replace(tzinfo=timezone.utc)) > timedelta(days=FAILED_TTL_DAYS):
                    print(f"Deleting failed job {j.metadata.name}")
                    try:
                        b1.delete_namespaced_job(
                            name=j.metadata.name,
                            namespace=NAMESPACE,
                            propagation_policy="Background",
                        )
                    except Exception as e:
                        print(f"Failed to delete failed job {j.metadata.name}: {e}")

        # Delete evicted pods
        pods = core.list_namespaced_pod(NAMESPACE).items
        for p in pods:
            st = p.status
            if st and st.phase == "Failed" and st.reason == "Evicted":
                print(f"Deleting evicted pod {p.metadata.name}")
                try:
                    core.delete_namespaced_pod(p.metadata.name, NAMESPACE)
                except Exception as e:
                    print(f"Failed to delete pod {p.metadata.name}: {e}")

    if __name__ == "__main__":
        main()

  deployer.py: |
    import os
    from kubernetes import client, config

    NAMESPACE = os.getenv("NAMESPACE", "news-analyzer")
    COMPONENT = os.getenv("COMPONENT", "all")  # scraper|extractor|notifier|summarizer|all
    TAG = os.getenv("IMAGE_TAG", "latest")
    # Default to existing Docker Hub repo used in manifests; override to ghcr if desired
    IMAGE_PREFIX = os.getenv("IMAGE_PREFIX", "caedus90/news-analyzer")

    def load_kube_config():
        try:
            config.load_incluster_config()
        except Exception:
            config.load_kube_config()

    def image_for(component: str) -> str:
        return f"{IMAGE_PREFIX}-{component}:{TAG}"

    def patch_cronjob_image(batch: client.BatchV1Api, name: str, container: str, image: str):
        body = {
            "spec": {
                "jobTemplate": {
                    "spec": {
                        "template": {
                            "spec": {
                                "containers": [
                                    {"name": container, "image": image}
                                ]
                            }
                        }
                    }
                }
            }
        }

  backfill_controller.sh: |
    #!/usr/bin/env bash
    set -euo pipefail

    ns=${NAMESPACE:-news-analyzer}
    start=${START:-2025-01-01}
    end=${END:-2025-12-31}
    split=${SPLIT:-weekly}
    pubs=${PUBLICATIONS:-"Smyth County News & Messenger,The News & Press,The Bland County Messenger,The Floyd Press,Wytheville Enterprise,Washington County News"}
    force=${FORCE:-1}
    max_new=${MAX_NEW_PER_RUN:-5}
    req_cpu=${REQ_CPU:-2}
    req_mem=${REQ_MEM:-1Gi}
    lim_cpu=${LIM_CPU:-2}
    lim_mem=${LIM_MEM:-3Gi}
    pw_trace=${PW_TRACE:-0}
    par=${SCRAPER_PARALLELISM:-2}
    loop_sleep=${LOOP_SLEEP:-600}

    while true; do
      # Auto-tune if OOMs seen
      oom=$(kubectl get pods -n "$ns" -l component=scraper,type=backfill -o json 2>/dev/null | grep -c OOMKilled || true)
      if [ "$oom" -gt 0 ]; then
        par=1; lim_mem=4Gi
      fi

      # Capacity from quota
      limit=$(kubectl get resourcequota news-analyzer-quota -n "$ns" -o jsonpath='{.status.hard.count/jobs\.batch}' 2>/dev/null || true)
      [ -z "$limit" ] && limit=40
      used=$(kubectl get jobs -n "$ns" --no-headers 2>/dev/null | wc -l | tr -d ' ')
      cap=$((limit - used)); [ $cap -lt 0 ] && cap=0; [ $cap -gt $max_new ] && cap=$max_new
      created=0

      cur="$start"
      while [ "$cur" \<="$end" ] && [ $created -lt $cap ]; do
        # compute window
        if [ "$split" = "daily" ]; then
          win_s="$cur"; win_e="$cur"
        elif [ "$split" = "biweekly" ]; then
          win_s="$cur"; win_e=$(date -d "$cur +13 days" +%Y-%m-%d); [ "$win_e" \> "$end" ] && win_e="$end"
        else
          win_s="$cur"; win_e=$(date -d "$cur +6 days" +%Y-%m-%d); [ "$win_e" \> "$end" ] && win_e="$end"
        fi
        # require Wed/Sat in window
        keep=0; d="$win_s"; while [ "$d" \<="$win_e" ]; do dow=$(date -d "$d" +%u); [ "$dow" = "3" -o "$dow" = "6" ] && keep=1 && break; d=$(date -d "$d +1 day" +%Y-%m-%d); done
        ws=$(date -d "$win_s" +%Y%m%d); we=$(date -d "$win_e" +%Y%m%d)
        if [ $keep -eq 1 ]; then
          # SCRAPER job if not exists
          if ! kubectl get jobs -n "$ns" -l component=scraper,type=backfill,win-start=$ws,win-end=$we -o name | grep -q .; then
            cat <<YAML | kubectl create -f -
apiVersion: batch/v1
kind: Job
metadata:
  generateName: scraper-backfill-
  namespace: $ns
  labels:
    app: news-analyzer
    component: scraper
    type: backfill
    win-start: "$ws"
    win-end: "$we"
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 172800
  template:
    metadata:
      labels:
        app: news-analyzer
        component: scraper
        type: backfill
        win-start: "$ws"
        win-end: "$we"
    spec:
      restartPolicy: Never
      serviceAccountName: news-analyzer-ops-bot
      imagePullSecrets:
      - name: harbor-regcred
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      volumes:
      - name: session-storage
        emptyDir: {}
      - name: scraper-login-override
        configMap:
          name: scraper-login-override
      - name: scraper-discover-override
        configMap:
          name: scraper-discover-override
      containers:
      - name: scraper
        image: registry.harbor.lan/library/news-analyzer-scraper:latest
        imagePullPolicy: Always
        env:
        - name: PW_TRACE
          value: "$pw_trace"
        - name: SCRAPER_PARALLELISM
          value: "$par"
        - name: HOME
          value: /home/scraper
        - name: PLAYWRIGHT_BROWSERS_PATH
          value: /home/scraper/.cache/ms-playwright
        - name: EEDITION_USER
          valueFrom:
            secretKeyRef:
              name: news-analyzer-secrets
              key: EEDITION_USER
        - name: EEDITION_PASS
          valueFrom:
            secretKeyRef:
              name: news-analyzer-secrets
              key: EEDITION_PASS
        - name: SMARTPROXY_USERNAME
          valueFrom:
            secretKeyRef:
              name: news-analyzer-secrets
              key: SMARTPROXY_USERNAME
        - name: SMARTPROXY_PASSWORD
          valueFrom:
            secretKeyRef:
              name: news-analyzer-secrets
              key: SMARTPROXY_PASSWORD
        - name: SMARTPROXY_HOST
          valueFrom:
            configMapKeyRef:
              name: news-analyzer-config
              key: SMARTPROXY_HOST
        - name: MINIO_ENDPOINT
          valueFrom:
            configMapKeyRef:
              name: news-analyzer-config
              key: MINIO_ENDPOINT
        - name: MINIO_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: news-analyzer-secrets
              key: MINIO_ACCESS_KEY
        - name: MINIO_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: news-analyzer-secrets
              key: MINIO_SECRET_KEY
        - name: MINIO_BUCKET
          valueFrom:
            configMapKeyRef:
              name: news-analyzer-config
              key: MINIO_BUCKET
        - name: SCRAPER_USER_AGENT
          valueFrom:
            configMapKeyRef:
              name: news-analyzer-config
              key: SCRAPER_USER_AGENT
        - name: START_DATE
          value: "$win_s"
        - name: END_DATE
          value: "$win_e"
        - name: FORCE_DOWNLOAD
          value: "$force"
        - name: PUBLICATIONS
          value: "$pubs"
        resources:
          requests:
            memory: "$req_mem"
            cpu: "$req_cpu"
          limits:
            memory: "$lim_mem"
            cpu: "$lim_cpu"
        command:
        - /bin/sh
        - -c
        - |
          set -e
          mkdir -p /app/storage
          python - <<'PY' > /tmp/download-dates.txt
          from datetime import datetime, timedelta
          import os
          start = datetime.strptime(os.environ['START_DATE'], '%Y-%m-%d').date()
          end = datetime.strptime(os.environ['END_DATE'], '%Y-%m-%d').date()
          cur = start
          while cur <= end:
              if cur.weekday() in (2, 5):
                  print(cur.isoformat())
              cur += timedelta(days=1)
          PY
          PUB_LIST="${PUBLICATIONS}"
          while read d; do
            [ -z "$d" ] && continue
            echo "Processing edition $d"
            extra=""; [ "$FORCE_DOWNLOAD" = "1" ] && extra="--force"
            OLD_IFS="$IFS"; IFS=,; for pub in $PUB_LIST; do
              pub_trim=$(echo "$pub" | sed -e "s/^ *//" -e "s/ *$//")
              [ -z "$pub_trim" ] && continue
              echo "  -> $pub_trim"
              python -m scraper.downloader --date "$d" $extra --publication "$pub_trim" --storage /app/storage/storage_state.json
              sleep 1
            done; IFS="$OLD_IFS"
          done < /tmp/download-dates.txt
          volumeMounts:
          - name: session-storage
            mountPath: /app/storage
          - name: scraper-login-override
            mountPath: /app/scraper/login.py
            subPath: login.py
          - name: scraper-discover-override
            mountPath: /app/scraper/discover.py
            subPath: discover.py
YAML
            created=$((created+1))
          fi

          # EXTRACTOR job if not exists
          if ! kubectl get jobs -n "$ns" -l component=extractor,type=backfill,win-start=$ws,win-end=$we -o name | grep -q .; then
            cat <<YAML | kubectl create -f -
apiVersion: batch/v1
kind: Job
metadata:
  generateName: extractor-backfill-
  namespace: $ns
  labels:
    app: news-analyzer
    component: extractor
    type: backfill
    win-start: "$ws"
    win-end: "$we"
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 172800
  template:
    metadata:
      labels:
        app: news-analyzer
        component: extractor
        type: backfill
        win-start: "$ws"
        win-end: "$we"
    spec:
      restartPolicy: Never
      imagePullSecrets:
      - name: harbor-regcred
      containers:
      - name: extractor
        image: registry.harbor.lan/library/news-analyzer-extractor:latest
        imagePullPolicy: Always
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: news-analyzer-secrets
              key: DATABASE_URL
        - name: MINIO_ENDPOINT
          valueFrom:
            configMapKeyRef:
              name: news-analyzer-config
              key: MINIO_ENDPOINT
        - name: MINIO_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: news-analyzer-secrets
              key: MINIO_ACCESS_KEY
        - name: MINIO_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: news-analyzer-secrets
              key: MINIO_SECRET_KEY
        - name: MINIO_BUCKET
          valueFrom:
            configMapKeyRef:
              name: news-analyzer-config
              key: MINIO_BUCKET
        resources:
          requests:
            memory: 1Gi
            cpu: 500m
          limits:
            memory: 2Gi
            cpu: 1000m
        command:
        - /bin/sh
        - -c
        - |
          set -e
          start="$win_s"; end="$win_e"
          python - <<'PY' > /tmp/dates.txt
          import os
          from datetime import datetime, timedelta
          start = datetime.strptime(os.environ.get('START','%s'), '%%Y-%%m-%%d').date()
          end = datetime.strptime(os.environ.get('END','%s'), '%%Y-%%m-%%d').date()
          cur = start
          while cur <= end:
              print(cur.isoformat())
              cur += timedelta(days=1)
          PY
          while read d; do
            echo "Extracting $d"
            python -m processor --date "$d"
          done < /tmp/dates.txt
YAML
          fi
        fi

        # move to next window
        cur=$(date -d "$win_e +1 day" +%Y-%m-%d)
      done

      echo "controller: sleep $loop_sleep sec"; sleep "$loop_sleep"
    done

  backfill_topup.py: |
    import os
    from datetime import datetime, timedelta, date
    from typing import List, Tuple

    from kubernetes import client, config

    NAMESPACE = os.getenv("NAMESPACE", "news-analyzer")
    START = os.getenv("START", "2025-01-01")
    END = os.getenv("END", "2025-09-30")
    SPLIT = os.getenv("SPLIT", "weekly")  # weekly|daily|biweekly
    PUBLICATIONS = os.getenv(
        "PUBLICATIONS",
        "Smyth County News & Messenger,The News & Press,The Bland County Messenger,The Floyd Press,Wytheville Enterprise,Washington County News",
    )
    FORCE = os.getenv("FORCE", "0") in ("1", "true", "True")
    PW_TRACE = os.getenv("PW_TRACE", "0")
    SCRAPER_PARALLELISM = os.getenv("SCRAPER_PARALLELISM", "2")
    MAX_NEW_PER_RUN = int(os.getenv("MAX_NEW_PER_RUN", "5"))

    REQ_CPU = os.getenv("REQ_CPU", "2")
    REQ_MEM = os.getenv("REQ_MEM", "1Gi")
    LIM_CPU = os.getenv("LIM_CPU", "2")
    LIM_MEM = os.getenv("LIM_MEM", "3Gi")

    def load_kube_config():
        try:
            config.load_incluster_config()
        except Exception:
            config.load_kube_config()

    def parse_date(s: str) -> date:
        return datetime.strptime(s, "%Y-%m-%d").date()

    def iter_windows(start: date, end: date, unit: str):
        cur = start
        while cur <= end:
            if unit == "daily":
                s, e = cur, cur
            elif unit == "biweekly":
                s, e = cur, min(end, cur + timedelta(days=13))
            else:
                s, e = cur, min(end, cur + timedelta(days=6))
            # keep only windows with at least one Wed/Sat
            keep = False
            d = s
            while d <= e:
                if d.weekday() in (2, 5):
                    keep = True
                    break
                d += timedelta(days=1)
            if keep:
                yield s, e
            cur = e + timedelta(days=1)

    def job_exists(batch: client.BatchV1Api, s: date, e: date) -> bool:
        key = f"win-start={s.strftime('%Y%m%d')},win-end={e.strftime('%Y%m%d')}"
        jobs = batch.list_namespaced_job(
            NAMESPACE,
            label_selector=f"component=scraper,type=backfill,{key}",
        )
        return bool(jobs.items)

    def capacity(batch: client.BatchV1Api, core: client.CoreV1Api) -> int:
        # Try to respect the ResourceQuota count/jobs.batch if present
        try:
            rq = core.read_namespaced_resource_quota("news-analyzer-quota", NAMESPACE)
            hard = (rq.status and rq.status.hard) or (rq.spec and rq.spec.hard) or {}
            limit = int(hard.get("count/jobs.batch", 40))
        except Exception:
            limit = 40
        try:
            cur = batch.list_namespaced_job(NAMESPACE)
            used = len(cur.items)
        except Exception:
            used = 0
        return max(0, limit - used)

    def build_job(s: date, e: date) -> client.V1Job:
        meta = client.V1ObjectMeta(
            generate_name=f"scraper-backfill-",
            namespace=NAMESPACE,
            labels={
                "app": "news-analyzer",
                "component": "scraper",
                "type": "backfill",
                "win-start": s.strftime("%Y%m%d"),
                "win-end": e.strftime("%Y%m%d"),
            },
        )
        env = [
            client.V1EnvVar(name="PW_TRACE", value=PW_TRACE),
            client.V1EnvVar(name="SCRAPER_PARALLELISM", value=SCRAPER_PARALLELISM),
            client.V1EnvVar(name="HOME", value="/home/scraper"),
            client.V1EnvVar(name="PLAYWRIGHT_BROWSERS_PATH", value="/home/scraper/.cache/ms-playwright"),
            client.V1EnvVar(name="EEDITION_USER", value_from=client.V1EnvVarSource(secret_key_ref=client.V1SecretKeySelector(name="news-analyzer-secrets", key="EEDITION_USER"))),
            client.V1EnvVar(name="EEDITION_PASS", value_from=client.V1EnvVarSource(secret_key_ref=client.V1SecretKeySelector(name="news-analyzer-secrets", key="EEDITION_PASS"))),
            client.V1EnvVar(name="SMARTPROXY_USERNAME", value_from=client.V1EnvVarSource(secret_key_ref=client.V1SecretKeySelector(name="news-analyzer-secrets", key="SMARTPROXY_USERNAME"))),
            client.V1EnvVar(name="SMARTPROXY_PASSWORD", value_from=client.V1EnvVarSource(secret_key_ref=client.V1SecretKeySelector(name="news-analyzer-secrets", key="SMARTPROXY_PASSWORD"))),
            client.V1EnvVar(name="SMARTPROXY_HOST", value_from=client.V1EnvVarSource(config_map_key_ref=client.V1ConfigMapKeySelector(name="news-analyzer-config", key="SMARTPROXY_HOST"))),
            client.V1EnvVar(name="MINIO_ENDPOINT", value_from=client.V1EnvVarSource(config_map_key_ref=client.V1ConfigMapKeySelector(name="news-analyzer-config", key="MINIO_ENDPOINT"))),
            client.V1EnvVar(name="MINIO_ACCESS_KEY", value_from=client.V1EnvVarSource(secret_key_ref=client.V1SecretKeySelector(name="news-analyzer-secrets", key="MINIO_ACCESS_KEY"))),
            client.V1EnvVar(name="MINIO_SECRET_KEY", value_from=client.V1EnvVarSource(secret_key_ref=client.V1SecretKeySelector(name="news-analyzer-secrets", key="MINIO_SECRET_KEY"))),
            client.V1EnvVar(name="MINIO_BUCKET", value_from=client.V1EnvVarSource(config_map_key_ref=client.V1ConfigMapKeySelector(name="news-analyzer-config", key="MINIO_BUCKET"))),
            client.V1EnvVar(name="SCRAPER_USER_AGENT", value_from=client.V1EnvVarSource(config_map_key_ref=client.V1ConfigMapKeySelector(name="news-analyzer-config", key="SCRAPER_USER_AGENT"))),
            client.V1EnvVar(name="START_DATE", value=s.isoformat()),
            client.V1EnvVar(name="END_DATE", value=e.isoformat()),
            client.V1EnvVar(name="FORCE_DOWNLOAD", value="1" if FORCE else "0"),
            client.V1EnvVar(name="PUBLICATIONS", value=PUBLICATIONS),
        ]

        cmd = [
            "/bin/sh",
            "-c",
            "\n".join([
                "set -e",
                "mkdir -p /app/storage",
                "python - <<'PY' > /tmp/download-dates.txt",
                "from datetime import datetime, timedelta",
                "import os",
                "start = datetime.strptime(os.environ['START_DATE'], '%Y-%m-%d').date()",
                "end = datetime.strptime(os.environ['END_DATE'], '%Y-%m-%d').date()",
                "cur = start",
                "while cur <= end:",
                "    if cur.weekday() in (2, 5):",
                "        print(cur.isoformat())",
                "    cur += timedelta(days=1)",
                "PY",
                "PUB_LIST=\"${PUBLICATIONS}\"",
                "while read d; do",
                "  [ -z \"$d\" ] && continue",
                "  echo Processing edition $d",
                "  extra=\"\"; [ \"$FORCE_DOWNLOAD\" = \"1\" ] && extra=\"--force\"",
                "  OLD_IFS=\"$IFS\"; IFS=,; for pub in $PUB_LIST; do",
                "    pub_trim=$(echo \"$pub\" | sed -e 's/^ *//' -e 's/ *$//')",
                "    [ -z \"$pub_trim\" ] && continue",
                "    echo \"  -> $pub_trim\"",
                "    python -m scraper.downloader --date \"$d\" $extra --publication \"$pub_trim\" --storage /app/storage/storage_state.json",
                "    sleep 1",
                "  done; IFS=\"$OLD_IFS\"",
                "done < /tmp/download-dates.txt",
            ]),
        ]

        resources = client.V1ResourceRequirements(
            requests={"cpu": REQ_CPU, "memory": REQ_MEM},
            limits={"cpu": LIM_CPU, "memory": LIM_MEM},
        )

        c = client.V1Container(
            name="scraper",
            image="registry.harbor.lan/library/news-analyzer-scraper:latest",
            image_pull_policy="Always",
            env=env,
            command=cmd,
            resources=resources,
            volume_mounts=[
                client.V1VolumeMount(name="session-storage", mount_path="/app/storage"),
                client.V1VolumeMount(name="scraper-login-override", mount_path="/app/scraper/login.py", sub_path="login.py"),
                client.V1VolumeMount(name="scraper-discover-override", mount_path="/app/scraper/discover.py", sub_path="discover.py"),
            ],
        )

        pod = client.V1PodSpec(
            restart_policy="Never",
            image_pull_secrets=[client.V1LocalObjectReference(name="harbor-regcred")],
            security_context=client.V1PodSecurityContext(run_as_non_root=True, run_as_user=1000, fs_group=1000),
            containers=[c],
            volumes=[
                client.V1Volume(name="session-storage", empty_dir=client.V1EmptyDirVolumeSource()),
                client.V1Volume(name="scraper-login-override", config_map=client.V1ConfigMapVolumeSource(name="scraper-login-override")),
                client.V1Volume(name="scraper-discover-override", config_map=client.V1ConfigMapVolumeSource(name="scraper-discover-override")),
            ],
        )

        tpl = client.V1PodTemplateSpec(metadata=client.V1ObjectMeta(labels=meta.labels.copy()), spec=pod)
        spec = client.V1JobSpec(template=tpl, backoff_limit=0, ttl_seconds_after_finished=172800)
        return client.V1Job(api_version="batch/v1", kind="Job", metadata=meta, spec=spec)

    def main():
        load_kube_config()
        batch = client.BatchV1Api()
        core = client.CoreV1Api()

        start = parse_date(START)
        end = parse_date(END)

        cap = min(capacity(batch, core), MAX_NEW_PER_RUN)
        created = 0
        for s, e in iter_windows(start, end, SPLIT):
            if created >= cap:
                break
            if job_exists(batch, s, e):
                continue
            job = build_job(s, e)
            batch.create_namespaced_job(namespace=NAMESPACE, body=job)
            created += 1
        print(f"Backfill top-up created {created} new jobs (cap {cap}).")

    if __name__ == "__main__":
        main()
        batch.patch_namespaced_cron_job(name=name, namespace=NAMESPACE, body=body)

    def patch_deployment_image(apps: client.AppsV1Api, name: str, container: str, image: str):
        body = {
            "spec": {
                "template": {
                    "spec": {
                        "containers": [
                            {"name": container, "image": image}
                        ]
                    }
                }
            }
        }
        apps.patch_namespaced_deployment(name=name, namespace=NAMESPACE, body=body)

    def main():
        load_kube_config()
        batch = client.BatchV1Api()
        apps = client.AppsV1Api()

        targets = []
        if COMPONENT in ("all", "scraper"):
            targets.append(("cronjob", "news-analyzer-scraper", "scraper"))
        if COMPONENT in ("all", "extractor"):
            targets.append(("cronjob", "news-analyzer-extractor", "extractor"))
        if COMPONENT in ("all", "notifier"):
            targets.append(("cronjob", "news-analyzer-notifier", "notifier"))
        if COMPONENT in ("all", "summarizer"):
            targets.append(("deployment", "news-analyzer-summarizer", "summarizer"))

        for kind, name, container in targets:
            img = image_for(container)
            print(f"Updating {kind}/{name} container {container} -> {img}")
            if kind == "cronjob":
                patch_cronjob_image(batch, name, container, img)
            else:
                patch_deployment_image(apps, name, container, img)

        print("Done.")

    if __name__ == "__main__":
        main()
