apiVersion: batch/v1
kind: CronJob
metadata:
  name: news-analyzer-scraper
  namespace: news-analyzer
  labels:
    app: news-analyzer
    component: scraper
spec:
  # Run daily at 6:00 AM EST (10:00 UTC)
  schedule: "0 10 * * *"
  timeZone: "America/New_York"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 5
  startingDeadlineSeconds: 3600
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: news-analyzer
            component: scraper
        spec:
          restartPolicy: OnFailure
          imagePullSecrets:
          - name: harbor-regcred
          containers:
          - name: scraper
            image: registry.harbor.lan/library/news-analyzer-scraper:latest
            imagePullPolicy: Always
            command:
            - /bin/sh
            - -c
            - |
              chmod 755 /home/scraper
              DATE=$(date +%Y-%m-%d)
              python -m scraper.downloader --date $DATE --storage /app/storage/storage_state.json
            env:
            - name: PW_TRACE
              value: "0"
            - name: SCRAPER_PARALLELISM
              value: "2"
            - name: METRICS_LABEL_component
              value: scraper
            - name: METRICS_LABEL_namespace
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: METRICS_LABEL_pod
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: METRICS_LABEL_node
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: LOG_FORMAT
              value: json
            - name: METRICS_JOB_NAME
              value: scraper
            - name: METRICS_PUSHGATEWAY_URL
              value: ""
            - name: SMARTPROXY_STICKY
              value: "1"
            - name: HOME
              value: /home/scraper
            - name: PLAYWRIGHT_BROWSERS_PATH
              value: /home/scraper/.cache/ms-playwright
            - name: EEDITION_USER
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: EEDITION_USER
            - name: EEDITION_PASS
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: EEDITION_PASS
            - name: SMARTPROXY_USERNAME
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: SMARTPROXY_USERNAME
            - name: SMARTPROXY_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: SMARTPROXY_PASSWORD
            - name: SMARTPROXY_HOST
              valueFrom:
                configMapKeyRef:
                  name: news-analyzer-config
                  key: SMARTPROXY_HOST
            - name: MINIO_ENDPOINT
              valueFrom:
                configMapKeyRef:
                  name: news-analyzer-config
                  key: MINIO_ENDPOINT
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: MINIO_ACCESS_KEY
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: MINIO_SECRET_KEY
            - name: MINIO_BUCKET
              valueFrom:
                configMapKeyRef:
                  name: news-analyzer-config
                  key: MINIO_BUCKET
            - name: SCRAPER_USER_AGENT
              valueFrom:
                configMapKeyRef:
                  name: news-analyzer-config
                  key: SCRAPER_USER_AGENT
            resources:
              requests:
                memory: "768Mi"
                cpu: "500m"
              limits:
                memory: "2Gi"
                cpu: "1"
            volumeMounts:
            - name: session-storage
              mountPath: /app/storage
            - name: scraper-login-override
              mountPath: /app/scraper/login.py
              subPath: login.py
            - name: scraper-discover-override
              mountPath: /app/scraper/discover.py
              subPath: discover.py
          volumes:
          - name: session-storage
            emptyDir: {}
          - name: scraper-login-override
            configMap:
              name: scraper-login-override
          - name: scraper-discover-override
            configMap:
              name: scraper-discover-override
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            fsGroup: 1000
---
## PVC removed to stay within namespace quota; using emptyDir for session storage.
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: news-analyzer-auth-refresh
  namespace: news-analyzer
  labels:
    app: news-analyzer
    component: auth-refresh
spec:
  # Run weekly on Sundays at 5:00 AM EST (9:00 UTC)
  schedule: "0 9 * * 0"
  timeZone: "America/New_York"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 2
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: news-analyzer
            component: auth-refresh
        spec:
          restartPolicy: OnFailure
          imagePullSecrets:
          - name: harbor-regcred
          containers:
          - name: auth-refresh
            image: registry.harbor.lan/library/news-analyzer-scraper:latest
            imagePullPolicy: Always
            command:
            - /bin/sh
            - -c
            - |
              chmod 755 /home/scraper
              python -m scraper.login --storage /app/storage/storage_state.json
            env:
            - name: PW_TRACE
              value: "0"
            - name: METRICS_LABEL_component
              value: auth_refresh
            - name: METRICS_LABEL_namespace
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: METRICS_LABEL_pod
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: METRICS_LABEL_node
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: LOG_FORMAT
              value: json
            - name: METRICS_JOB_NAME
              value: auth_refresh
            - name: METRICS_PUSHGATEWAY_URL
              value: ""
            - name: SMARTPROXY_STICKY
              value: "1"
            - name: HOME
              value: /home/scraper
            - name: PLAYWRIGHT_BROWSERS_PATH
              value: /home/scraper/.cache/ms-playwright
            - name: EEDITION_USER
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: EEDITION_USER
            - name: EEDITION_PASS
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: EEDITION_PASS
            - name: SMARTPROXY_USERNAME
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: SMARTPROXY_USERNAME
            - name: SMARTPROXY_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: news-analyzer-secrets
                  key: SMARTPROXY_PASSWORD
            - name: SMARTPROXY_HOST
              valueFrom:
                configMapKeyRef:
                  name: news-analyzer-config
                  key: SMARTPROXY_HOST
           resources:
             requests:
                memory: "512Mi"
                cpu: "250m"
             limits:
                memory: "1.5Gi"
                cpu: "500m"
            volumeMounts:
            - name: session-storage
              mountPath: /app/storage
            - name: scraper-login-override
              mountPath: /app/scraper/login.py
              subPath: login.py
            - name: scraper-discover-override
              mountPath: /app/scraper/discover.py
              subPath: discover.py
          volumes:
          - name: session-storage
            emptyDir: {}
          - name: scraper-login-override
            configMap:
              name: scraper-login-override
          - name: scraper-discover-override
            configMap:
              name: scraper-discover-override
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            fsGroup: 1000
